{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOsBqMfRfl3EdETTxye3ZNm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marwahfaraj/Smart-Water-Quality-Monitoring-Using-IoT-and-Machine-Learning/blob/suryaWaterPrediction/notebooks/04_water_quality_prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Water Quality Predection Model\n",
        "\n",
        "## AAI-530 Final Project - Machine Learning Method 3\n",
        "\n",
        "This notebook implements a machine learning predection model to predict water quality status (Safe/Warning/Unsafe) based on sensor readings.\n",
        "\n",
        "**Objective**: Predict water quality status using multiple sensor inputs\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "24jZodhs3Fp6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/marwahfaraj/Smart-Water-Quality-Monitoring-Using-IoT-and-Machine-Learning.git"
      ],
      "metadata": {
        "collapsed": true,
        "id": "ivOkomvn36Vs",
        "outputId": "93d05a00-3016-4269-8fdf-9b719e369ab2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Smart-Water-Quality-Monitoring-Using-IoT-and-Machine-Learning'...\n",
            "remote: Enumerating objects: 72, done.\u001b[K\n",
            "remote: Counting objects: 100% (72/72), done.\u001b[K\n",
            "remote: Compressing objects: 100% (64/64), done.\u001b[K\n",
            "remote: Total 72 (delta 11), reused 59 (delta 6), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (72/72), 31.01 MiB | 15.54 MiB/s, done.\n",
            "Resolving deltas: 100% (11/11), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "dbceArK82MjE",
        "outputId": "1dcdc9b9-4768-4c9e-b087-846560b9ede4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Libraries loaded successfully!\n"
          ]
        }
      ],
      "source": [
        "# Import required libraries\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import seaborn as sns\n",
        "import os\n",
        "import warnings\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "from tensorflow.keras.layers import GRU, Input, Dense, Dropout\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "np.random.seed(42)\n",
        "\n",
        "print(\"Libraries loaded successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Load and Prepare Data"
      ],
      "metadata": {
        "id": "KgFX_HMg3jTW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load raw data and preprocess (if processed data not available)\n",
        "DATA_DIR = \"/content/Smart-Water-Quality-Monitoring-Using-IoT-and-Machine-Learning/outputs/water_quality_processed.csv\"\n",
        "# DATA_DIR = '../outputs/water_quality_processed.csv'\n",
        "\n",
        "# Load data\n",
        "df = pd.read_csv(DATA_DIR)\n",
        "\n",
        "print(f\"Loaded {len(df):,} records from {df['Station'].nunique()} stations\")\n",
        "print(f\"Date range: {df['Timestamp'].min()} to {df['Timestamp'].max()}\\n\")\n",
        "\n",
        "print(df.head())"
      ],
      "metadata": {
        "id": "SlSKH-y83Owk",
        "outputId": "c311f333-4c91-41df-b9b4-7e4fdc5ccaf1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 295,754 records from 11 stations\n",
            "Date range: 2016-03-01 00:00:00 to 2020-04-01 23:00:00\n",
            "\n",
            "             Timestamp   Q  Conductivity  NO3  Temp  Turbidity  Level  \\\n",
            "0  2017-05-11 14:00:00 NaN      13502.10  NaN   NaN      12.79    NaN   \n",
            "1  2017-05-11 15:00:00 NaN      10304.00  NaN   NaN      11.93    NaN   \n",
            "2  2017-05-11 16:00:00 NaN       5588.08  NaN   NaN      10.34    NaN   \n",
            "3  2017-05-11 17:00:00 NaN      13937.00  NaN   NaN      24.02    NaN   \n",
            "4  2017-05-11 18:00:00 NaN      44761.40  NaN   NaN      18.46    NaN   \n",
            "\n",
            "   Dayofweek  Month                         Station  ...  \\\n",
            "0          3      5  Johnstone River Coquette Point  ...   \n",
            "1          3      5  Johnstone River Coquette Point  ...   \n",
            "2          3      5  Johnstone River Coquette Point  ...   \n",
            "3          3      5  Johnstone River Coquette Point  ...   \n",
            "4          3      5  Johnstone River Coquette Point  ...   \n",
            "\n",
            "   Turbidity_rolling_mean_12h Turbidity_rolling_std_12h  \\\n",
            "0                   12.790000                       NaN   \n",
            "1                   12.360000                  0.608112   \n",
            "2                   11.686667                  1.242994   \n",
            "3                   14.770000                  6.249624   \n",
            "4                   15.508000                  5.658319   \n",
            "\n",
            "   Turbidity_rolling_mean_24h  Turbidity_rolling_std_24h  \\\n",
            "0                   12.790000                        NaN   \n",
            "1                   12.360000                   0.608112   \n",
            "2                   11.686667                   1.242994   \n",
            "3                   14.770000                   6.249624   \n",
            "4                   15.508000                   5.658319   \n",
            "\n",
            "   Conductivity_rolling_mean_6h  Conductivity_rolling_std_6h  \\\n",
            "0                     13502.100                          NaN   \n",
            "1                     11903.050                  2261.398197   \n",
            "2                      9798.060                  3981.194494   \n",
            "3                     10832.795                  3853.480567   \n",
            "4                     17618.516                 15535.991498   \n",
            "\n",
            "   Conductivity_rolling_mean_12h  Conductivity_rolling_std_12h  \\\n",
            "0                      13502.100                           NaN   \n",
            "1                      11903.050                   2261.398197   \n",
            "2                       9798.060                   3981.194494   \n",
            "3                      10832.795                   3853.480567   \n",
            "4                      17618.516                  15535.991498   \n",
            "\n",
            "   Conductivity_rolling_mean_24h  Conductivity_rolling_std_24h  \n",
            "0                      13502.100                           NaN  \n",
            "1                      11903.050                   2261.398197  \n",
            "2                       9798.060                   3981.194494  \n",
            "3                      10832.795                   3853.480567  \n",
            "4                      17618.516                  15535.991498  \n",
            "\n",
            "[5 rows x 41 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "id": "NxstVQdt3ofQ",
        "outputId": "f7bb4965-fccd-44aa-9773-aadbd982dcdf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Timestamp', 'Q', 'Conductivity', 'NO3', 'Temp', 'Turbidity', 'Level',\n",
              "       'Dayofweek', 'Month', 'Station', 'Hour', 'Quality_Status', 'Year',\n",
              "       'DayOfWeek', 'DayOfMonth', 'WeekOfYear', 'IsWeekend', 'Hour_sin',\n",
              "       'Hour_cos', 'Month_sin', 'Month_cos', 'Turbidity_lag_1h',\n",
              "       'Turbidity_lag_6h', 'Turbidity_lag_12h', 'Turbidity_lag_24h',\n",
              "       'Conductivity_lag_1h', 'Conductivity_lag_6h', 'Conductivity_lag_12h',\n",
              "       'Conductivity_lag_24h', 'Turbidity_rolling_mean_6h',\n",
              "       'Turbidity_rolling_std_6h', 'Turbidity_rolling_mean_12h',\n",
              "       'Turbidity_rolling_std_12h', 'Turbidity_rolling_mean_24h',\n",
              "       'Turbidity_rolling_std_24h', 'Conductivity_rolling_mean_6h',\n",
              "       'Conductivity_rolling_std_6h', 'Conductivity_rolling_mean_12h',\n",
              "       'Conductivity_rolling_std_12h', 'Conductivity_rolling_mean_24h',\n",
              "       'Conductivity_rolling_std_24h'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Feature Selection and Sequence Creation"
      ],
      "metadata": {
        "id": "LCrFSwquGHR5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "target_col = \"Turbidity\"\n",
        "drop_cols = [\n",
        "    \"Timestamp\",\n",
        "    \"Quality_Status\",     # leakage / label-like\n",
        "    \"Turbidity\",          # target\n",
        "    \"Dayofweek\",          # drop one of the duplicates\n",
        "    \"Month\",              # you already have Month_sin/cos (optional)\n",
        "    \"Hour\",               # you already have Hour_sin/cos (optional)\n",
        "    \"DayOfWeek\",          # keep only one of Dayofweek/DayOfWeek (choose one)\n",
        "]\n",
        "\n",
        "feature_cols = [c for c in df.columns if c not in drop_cols]\n",
        "print(\"Num candidate features:\", len(feature_cols))\n",
        "print(feature_cols)\n"
      ],
      "metadata": {
        "id": "TasqJ4sHFXZs",
        "outputId": "d4cd0141-02f4-41c7-c174-be70b6153609",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num candidate features: 34\n",
            "['Q', 'Conductivity', 'NO3', 'Temp', 'Level', 'Station', 'Year', 'DayOfMonth', 'WeekOfYear', 'IsWeekend', 'Hour_sin', 'Hour_cos', 'Month_sin', 'Month_cos', 'Turbidity_lag_1h', 'Turbidity_lag_6h', 'Turbidity_lag_12h', 'Turbidity_lag_24h', 'Conductivity_lag_1h', 'Conductivity_lag_6h', 'Conductivity_lag_12h', 'Conductivity_lag_24h', 'Turbidity_rolling_mean_6h', 'Turbidity_rolling_std_6h', 'Turbidity_rolling_mean_12h', 'Turbidity_rolling_std_12h', 'Turbidity_rolling_mean_24h', 'Turbidity_rolling_std_24h', 'Conductivity_rolling_mean_6h', 'Conductivity_rolling_std_6h', 'Conductivity_rolling_mean_12h', 'Conductivity_rolling_std_12h', 'Conductivity_rolling_mean_24h', 'Conductivity_rolling_std_24h']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.sort_values(\"Timestamp\").reset_index(drop=True)\n",
        "\n",
        "n = len(df)\n",
        "train_end = int(n*0.7)\n",
        "val_end = int(n*0.85)\n",
        "\n",
        "train_df = df.iloc[:train_end]\n",
        "val_df = df.iloc[train_end:val_end]\n",
        "test_df = df.iloc[val_end:]"
      ],
      "metadata": {
        "id": "fgbaqiJ2FkL_"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cleaning the data set for NA values.\n",
        "train_clean = train_df.dropna(subset=[target_col]).copy()\n",
        "\n",
        "X_train = train_clean[feature_cols].copy()\n",
        "\n",
        "# hot encoding the column values because some columns may contain\n",
        "# string values, where RFR will accept only the numerical values.\n",
        "X_train = pd.get_dummies(X_train, drop_first=True)\n",
        "y_train = train_clean[target_col].values\n",
        "\n",
        "rf = RandomForestRegressor(\n",
        "    n_estimators=80,\n",
        "    random_state=42,\n",
        "    n_jobs=-1,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "rf.fit(X_train, y_train)\n",
        "\n",
        "importances = pd.Series(rf.feature_importances_, index = X_train.columns).sort_values(ascending=False)\n"
      ],
      "metadata": {
        "id": "Mvtuc39zHZ9K",
        "outputId": "ec88d775-e1aa-4eb3-8326-a8db4348c93c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:  6.9min\n",
            "[Parallel(n_jobs=-1)]: Done  80 out of  80 | elapsed: 10.8min finished\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Top 20 features\n",
        "importances.head(20)\n"
      ],
      "metadata": {
        "id": "D3L2TecrH8rA",
        "outputId": "712776f2-8400-4c38-b465-c3a35825849f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 711
        }
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Turbidity_rolling_mean_6h       0.742123\n",
              "Turbidity_lag_1h                0.147415\n",
              "Turbidity_rolling_std_6h        0.021037\n",
              "Turbidity_lag_24h               0.014720\n",
              "Q                               0.012781\n",
              "Turbidity_rolling_std_12h       0.009229\n",
              "Level                           0.005743\n",
              "Turbidity_lag_12h               0.004128\n",
              "Conductivity                    0.004072\n",
              "Conductivity_lag_1h             0.003897\n",
              "Turbidity_lag_6h                0.003452\n",
              "Turbidity_rolling_mean_12h      0.003024\n",
              "Conductivity_rolling_std_6h     0.002473\n",
              "Turbidity_rolling_std_24h       0.002454\n",
              "Conductivity_lag_6h             0.002235\n",
              "Conductivity_lag_12h            0.002033\n",
              "Turbidity_rolling_mean_24h      0.002031\n",
              "Conductivity_lag_24h            0.002005\n",
              "Conductivity_rolling_std_12h    0.001623\n",
              "Hour_cos                        0.001562\n",
              "dtype: float64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Turbidity_rolling_mean_6h</th>\n",
              "      <td>0.742123</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Turbidity_lag_1h</th>\n",
              "      <td>0.147415</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Turbidity_rolling_std_6h</th>\n",
              "      <td>0.021037</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Turbidity_lag_24h</th>\n",
              "      <td>0.014720</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Q</th>\n",
              "      <td>0.012781</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Turbidity_rolling_std_12h</th>\n",
              "      <td>0.009229</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Level</th>\n",
              "      <td>0.005743</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Turbidity_lag_12h</th>\n",
              "      <td>0.004128</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Conductivity</th>\n",
              "      <td>0.004072</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Conductivity_lag_1h</th>\n",
              "      <td>0.003897</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Turbidity_lag_6h</th>\n",
              "      <td>0.003452</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Turbidity_rolling_mean_12h</th>\n",
              "      <td>0.003024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Conductivity_rolling_std_6h</th>\n",
              "      <td>0.002473</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Turbidity_rolling_std_24h</th>\n",
              "      <td>0.002454</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Conductivity_lag_6h</th>\n",
              "      <td>0.002235</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Conductivity_lag_12h</th>\n",
              "      <td>0.002033</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Turbidity_rolling_mean_24h</th>\n",
              "      <td>0.002031</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Conductivity_lag_24h</th>\n",
              "      <td>0.002005</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Conductivity_rolling_std_12h</th>\n",
              "      <td>0.001623</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Hour_cos</th>\n",
              "      <td>0.001562</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> float64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "top_k = 20\n",
        "top_features = importances.head(top_k).index.tolist()\n",
        "top_features"
      ],
      "metadata": {
        "id": "NVmoBM0aOVcH",
        "outputId": "2d45335c-42da-4b17-bd28-58c368d5eba2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Turbidity_rolling_mean_6h',\n",
              " 'Turbidity_lag_1h',\n",
              " 'Turbidity_rolling_std_6h',\n",
              " 'Turbidity_lag_24h',\n",
              " 'Q',\n",
              " 'Turbidity_rolling_std_12h',\n",
              " 'Level',\n",
              " 'Turbidity_lag_12h',\n",
              " 'Conductivity',\n",
              " 'Conductivity_lag_1h',\n",
              " 'Turbidity_lag_6h',\n",
              " 'Turbidity_rolling_mean_12h',\n",
              " 'Conductivity_rolling_std_6h',\n",
              " 'Turbidity_rolling_std_24h',\n",
              " 'Conductivity_lag_6h',\n",
              " 'Conductivity_lag_12h',\n",
              " 'Turbidity_rolling_mean_24h',\n",
              " 'Conductivity_lag_24h',\n",
              " 'Conductivity_rolling_std_12h',\n",
              " 'Hour_cos']"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove redundant features\n",
        "\n",
        "corr = train_df[top_features].corr().abs()\n",
        "upper = corr.where(np.triu(np.ones(corr.shape), k=1).astype(bool))\n",
        "\n",
        "to_drop = [col for col in upper.columns if any(upper[col]> 0.95)]\n",
        "final_features = [f for f in top_features if f not in to_drop]\n",
        "\n",
        "print(\"Dropped due to high correlation:\", to_drop)\n",
        "print(\"Final Features:\", final_features)"
      ],
      "metadata": {
        "id": "dQhFg2BhOfel",
        "outputId": "0f35a28f-8277-4096-87c1-1cf865d8dacd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dropped due to high correlation: ['Turbidity_lag_1h', 'Conductivity_lag_1h', 'Turbidity_rolling_mean_12h', 'Turbidity_rolling_mean_24h', 'Conductivity_lag_24h']\n",
            "Final Features: ['Turbidity_rolling_mean_6h', 'Turbidity_rolling_std_6h', 'Turbidity_lag_24h', 'Q', 'Turbidity_rolling_std_12h', 'Level', 'Turbidity_lag_12h', 'Conductivity', 'Turbidity_lag_6h', 'Conductivity_rolling_std_6h', 'Turbidity_rolling_std_24h', 'Conductivity_lag_6h', 'Conductivity_lag_12h', 'Conductivity_rolling_std_12h', 'Hour_cos']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(top_features), \"->\", len(final_features))\n",
        "print(\"Any non-numeric in final_features?\",\n",
        "      train_df[final_features].select_dtypes(include=[\"object\"]).columns.tolist())"
      ],
      "metadata": {
        "id": "rBWXT3l0UE_Y",
        "outputId": "ba141672-d882-48c7-f6ce-f0dd1695d7c2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20 -> 15\n",
            "Any non-numeric in final_features? []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Sequence Creation"
      ],
      "metadata": {
        "id": "ZN6_FkCUVDwY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = df[final_features]\n",
        "y = df[target_col]\n",
        "\n",
        "valid_idx = X.notna().all(axis=1) & y.notna()\n",
        "X = X.loc[valid_idx]\n",
        "y = y.loc[valid_idx]\n",
        "\n",
        "scaler_X = MinMaxScaler()\n",
        "scaler_y = MinMaxScaler()\n",
        "\n",
        "X_scaled = scaler_X.fit_transform(X)\n",
        "y_scaled = scaler_y.fit_transform(y.values.reshape(-1, 1))"
      ],
      "metadata": {
        "id": "9oFHjhdQVDK-"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_sequences(X, y, seq_len):\n",
        "  Xs,ys = [],[]\n",
        "  for i in range(len(X) - seq_len):\n",
        "    Xs.append(X[i:i+seq_len])\n",
        "    ys.append(y[i+seq_len])\n",
        "  return np.array(Xs), np.array(ys)\n",
        "\n",
        "SEQUENCE_LENGTH = 24\n",
        "\n",
        "X_seq, y_seq = create_sequences(X_scaled, y_scaled, SEQUENCE_LENGTH)\n",
        "\n",
        "print(X_seq.shape)\n",
        "print(y_seq.shape)"
      ],
      "metadata": {
        "id": "rOLk_Cb-V_nN",
        "outputId": "dc642123-3b3e-4a1c-ff3d-c07b4d7ec1f3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(80203, 24, 15)\n",
            "(80203, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, y_train = X_seq[:train_end], y_seq[:train_end]\n",
        "X_val, y_val = X_seq[train_end:val_end], y_seq[train_end:val_end]\n",
        "X_test, y_test = X_seq[val_end:], y_seq[val_end:]\n",
        "\n",
        "print(\"Train:\", X_train.shape, y_train.shape)\n",
        "print(\"Val  :\", X_val.shape, y_val.shape)\n",
        "print(\"Test :\", X_test.shape, y_test.shape)"
      ],
      "metadata": {
        "id": "tH7An2LCYEdb",
        "outputId": "f388b477-3648-40c0-ea73-e1c2d7c97e17",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: (80203, 24, 15) (80203, 1)\n",
            "Val  : (0, 24, 15) (0, 1)\n",
            "Test : (0, 24, 15) (0, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. GRU Model"
      ],
      "metadata": {
        "id": "RptoBF8BWs7C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_gru_model(sequence_length, n_features, units_1=64, units_2=32, dropout_rate=0.2, lr=0.001):\n",
        "    \"\"\"\n",
        "    GRU model for time series regression (predict Turbidity).\n",
        "    Input shape: (sequence_length, n_features)\n",
        "    Output: single value (next turbidity)\n",
        "    \"\"\"\n",
        "    model = Sequential([\n",
        "        Input(shape=(sequence_length, n_features)),\n",
        "\n",
        "        GRU(units_1, return_sequences=True),\n",
        "        Dropout(dropout_rate),\n",
        "\n",
        "        GRU(units_2, return_sequences=False),\n",
        "        Dropout(dropout_rate),\n",
        "\n",
        "        Dense(16, activation='relu'),\n",
        "        Dense(1)  # regression output\n",
        "    ])\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=Adam(learning_rate=lr),\n",
        "        loss='mse',\n",
        "        metrics=['mae']\n",
        "    )\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "dHqpzyX_USF9"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 64\n",
        "EPOCHS = 50\n",
        "\n",
        "callbacks = [\n",
        "    EarlyStopping(\n",
        "        monitor=\"val_loss\",\n",
        "        patience=8,\n",
        "        restore_best_weights=True\n",
        "    ),\n",
        "    ReduceLROnPlateau(\n",
        "        monitor=\"val_loss\",\n",
        "        factor=0.5,\n",
        "        patience=3,\n",
        "        min_lr=1e-6,\n",
        "        verbose=1\n",
        "    )\n",
        "]\n",
        "\n",
        "gru_model = build_gru_model(SEQUENCE_LENGTH, X_train.shape[2], units_1=64, units_2=32, dropout_rate=0.2, lr=0.001)\n",
        "\n",
        "gru_model.summary()\n",
        "\n",
        "gru_history = gru_model.fit(\n",
        "    X_train, y_train,\n",
        "    epochs = EPOCHS,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    validation_data=(X_val, y_val),\n",
        "    callbacks=callbacks,\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "id": "aY0yXDwHUgmF",
        "outputId": "9aa29572-e726-47e8-9b63-1311f46158b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ gru (\u001b[38;5;33mGRU\u001b[0m)                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │        \u001b[38;5;34m15,552\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ gru_1 (\u001b[38;5;33mGRU\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m9,408\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │           \u001b[38;5;34m528\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m17\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ gru (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">15,552</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ gru_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">9,408</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m25,505\u001b[0m (99.63 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">25,505</span> (99.63 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m25,505\u001b[0m (99.63 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">25,505</span> (99.63 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - loss: 0.0037 - mae: 0.0395 - learning_rate: 0.0010\n",
            "Epoch 2/50\n",
            "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 16ms/step - loss: 0.0030 - mae: 0.0347 - learning_rate: 0.0010\n",
            "Epoch 3/50\n",
            "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - loss: 0.0031 - mae: 0.0347 - learning_rate: 0.0010\n",
            "Epoch 4/50\n",
            "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - loss: 0.0031 - mae: 0.0344 - learning_rate: 0.0010\n",
            "Epoch 5/50\n",
            "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - loss: 0.0030 - mae: 0.0342 - learning_rate: 0.0010\n",
            "Epoch 6/50\n",
            "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - loss: 0.0030 - mae: 0.0337 - learning_rate: 0.0010\n",
            "Epoch 7/50\n",
            "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0030 - mae: 0.0338 - learning_rate: 0.0010\n",
            "Epoch 8/50\n",
            "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - loss: 0.0029 - mae: 0.0332 - learning_rate: 0.0010\n",
            "Epoch 9/50\n",
            "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - loss: 0.0029 - mae: 0.0331 - learning_rate: 0.0010\n",
            "Epoch 10/50\n",
            "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - loss: 0.0028 - mae: 0.0327 - learning_rate: 0.0010\n",
            "Epoch 11/50\n",
            "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 13ms/step - loss: 0.0028 - mae: 0.0328 - learning_rate: 0.0010\n",
            "Epoch 12/50\n",
            "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - loss: 0.0029 - mae: 0.0327 - learning_rate: 0.0010\n",
            "Epoch 13/50\n",
            "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - loss: 0.0028 - mae: 0.0323 - learning_rate: 0.0010\n",
            "Epoch 14/50\n",
            "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - loss: 0.0028 - mae: 0.0324 - learning_rate: 0.0010\n",
            "Epoch 15/50\n",
            "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - loss: 0.0028 - mae: 0.0325 - learning_rate: 0.0010\n",
            "Epoch 16/50\n",
            "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - loss: 0.0028 - mae: 0.0322 - learning_rate: 0.0010\n",
            "Epoch 17/50\n",
            "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - loss: 0.0028 - mae: 0.0321 - learning_rate: 0.0010\n",
            "Epoch 18/50\n",
            "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - loss: 0.0028 - mae: 0.0321 - learning_rate: 0.0010\n",
            "Epoch 19/50\n",
            "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - loss: 0.0027 - mae: 0.0318 - learning_rate: 0.0010\n",
            "Epoch 20/50\n",
            "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - loss: 0.0027 - mae: 0.0319 - learning_rate: 0.0010\n",
            "Epoch 21/50\n",
            "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 9ms/step - loss: 0.0027 - mae: 0.0317 - learning_rate: 0.0010\n",
            "Epoch 22/50\n",
            "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - loss: 0.0027 - mae: 0.0315 - learning_rate: 0.0010\n",
            "Epoch 23/50\n",
            "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - loss: 0.0027 - mae: 0.0316 - learning_rate: 0.0010\n",
            "Epoch 24/50\n",
            "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - loss: 0.0027 - mae: 0.0312 - learning_rate: 0.0010\n",
            "Epoch 25/50\n",
            "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - loss: 0.0026 - mae: 0.0312 - learning_rate: 0.0010\n",
            "Epoch 26/50\n",
            "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - loss: 0.0027 - mae: 0.0315 - learning_rate: 0.0010\n",
            "Epoch 27/50\n",
            "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 9ms/step - loss: 0.0025 - mae: 0.0307 - learning_rate: 0.0010\n",
            "Epoch 28/50\n",
            "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - loss: 0.0027 - mae: 0.0315 - learning_rate: 0.0010\n",
            "Epoch 29/50\n",
            "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - loss: 0.0026 - mae: 0.0308 - learning_rate: 0.0010\n",
            "Epoch 30/50\n",
            "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 35ms/step - loss: 0.0026 - mae: 0.0311 - learning_rate: 0.0010\n",
            "Epoch 31/50\n",
            "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - loss: 0.0026 - mae: 0.0309 - learning_rate: 0.0010\n",
            "Epoch 32/50\n",
            "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - loss: 0.0025 - mae: 0.0305 - learning_rate: 0.0010\n",
            "Epoch 33/50\n",
            "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 9ms/step - loss: 0.0026 - mae: 0.0307 - learning_rate: 0.0010\n",
            "Epoch 34/50\n",
            "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - loss: 0.0026 - mae: 0.0308 - learning_rate: 0.0010\n",
            "Epoch 35/50\n",
            "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - loss: 0.0026 - mae: 0.0307 - learning_rate: 0.0010\n",
            "Epoch 36/50\n",
            "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - loss: 0.0025 - mae: 0.0302 - learning_rate: 0.0010\n",
            "Epoch 37/50\n",
            "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - loss: 0.0025 - mae: 0.0304 - learning_rate: 0.0010\n",
            "Epoch 38/50\n",
            "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - loss: 0.0025 - mae: 0.0306 - learning_rate: 0.0010\n",
            "Epoch 39/50\n",
            "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - loss: 0.0025 - mae: 0.0303 - learning_rate: 0.0010\n",
            "Epoch 40/50\n",
            "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - loss: 0.0024 - mae: 0.0302 - learning_rate: 0.0010\n",
            "Epoch 41/50\n",
            "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - loss: 0.0025 - mae: 0.0303 - learning_rate: 0.0010\n",
            "Epoch 42/50\n",
            "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - loss: 0.0024 - mae: 0.0303 - learning_rate: 0.0010\n",
            "Epoch 43/50\n",
            "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - loss: 0.0024 - mae: 0.0302 - learning_rate: 0.0010\n",
            "Epoch 44/50\n",
            "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - loss: 0.0024 - mae: 0.0298 - learning_rate: 0.0010\n",
            "Epoch 45/50\n",
            "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - loss: 0.0024 - mae: 0.0299 - learning_rate: 0.0010\n",
            "Epoch 46/50\n",
            "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - loss: 0.0024 - mae: 0.0301 - learning_rate: 0.0010\n",
            "Epoch 47/50\n",
            "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 9ms/step - loss: 0.0024 - mae: 0.0300 - learning_rate: 0.0010\n",
            "Epoch 48/50\n",
            "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - loss: 0.0023 - mae: 0.0297 - learning_rate: 0.0010\n",
            "Epoch 49/50\n",
            "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - loss: 0.0024 - mae: 0.0296 - learning_rate: 0.0010\n",
            "Epoch 50/50\n",
            "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - loss: 0.0024 - mae: 0.0297 - learning_rate: 0.0010\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== Evaluate GRU (same inverse scaling approach as your LSTM) =====\n",
        "y_pred_scaled_gru = gru_model.predict(X_test, verbose=0)\n",
        "\n",
        "y_pred_gru = inverse_transform_target(\n",
        "    y_pred_scaled_gru, scaler, target_idx, len(available_features)\n",
        ")\n",
        "\n",
        "y_test_original = inverse_transform_target(\n",
        "    y_test.reshape(-1, 1), scaler, target_idx, len(available_features)\n",
        ")\n",
        "\n",
        "mse_gru = mean_squared_error(y_test_original, y_pred_gru)\n",
        "mae_gru = mean_absolute_error(y_test_original, y_pred_gru)\n",
        "r2_gru = r2_score(y_test_original, y_pred_gru)\n",
        "\n",
        "print(f\"GRU Test MSE: {mse_gru:.4f}\")\n",
        "print(f\"GRU Test MAE: {mae_gru:.4f}\")\n",
        "print(f\"GRU Test R² : {r2_gru:.4f}\")"
      ],
      "metadata": {
        "id": "C8CCI2YeUiXY",
        "outputId": "18dee4ef-c250-40e4-8290-1e04c3ec0c5c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        }
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "error",
          "ename": "UnboundLocalError",
          "evalue": "cannot access local variable 'batch_outputs' where it is not associated with a value",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3051417757.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# ===== Evaluate GRU (same inverse scaling approach as your LSTM) =====\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0my_pred_scaled_gru\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgru_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m y_pred_gru = inverse_transform_target(\n\u001b[1;32m      5\u001b[0m     \u001b[0my_pred_scaled_gru\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mavailable_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks)\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m         outputs = tree.map_structure_up_to(\n\u001b[0;32m--> 573\u001b[0;31m             \u001b[0mbatch_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpotentially_ragged_concat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    574\u001b[0m         )\n\u001b[1;32m    575\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert_to_np_if_not_ragged\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUnboundLocalError\u001b[0m: cannot access local variable 'batch_outputs' where it is not associated with a value"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "s1WhaJcscJzD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}